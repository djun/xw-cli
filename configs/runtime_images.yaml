# XW Runtime Images Configuration
# This file maps chip models to their inference engine Docker images
# for different CPU architectures.
#
# Structure:
#   <chip-model>:
#     <engine-name>:
#       <architecture>: <docker-image>
#
# Supported chip models:
#   - ascend-910b: Huawei Ascend 910B (training and inference)
#   - ascend-310p: Huawei Ascend 310P (inference only)
#
# Supported engines:
#   - vllm: vLLM inference engine
#   - mindie: MindIE inference engine (Huawei's optimized engine)
#   - mlguider: MLGuider inference engine
#
# Supported architectures:
#   - arm64: ARM 64-bit (aarch64)
#   - amd64: x86 64-bit (x86_64)
#
# You can customize these images based on your deployment requirements.
# The server will automatically select the correct image based on the
# current system's architecture.

version: "1.0"

# Ascend 910B configuration
ascend-910b:
  vllm:
    arm64: quay.io/ascend/vllm-ascend:v0.11.0rc0-arm64
    amd64: NONE
  mindie:
    arm64: harbor.tsingmao.com/xuanwu/mindie:2.2.RC1-800I-A2-py311-openeuler24.03-lts-arm64
    amd64: NONE
  mlguider:
    arm64: harbor.tsingmao.com/mlguider/release:0123-xw-arm64
    amd64: NONE

# Ascend 310P configuration
ascend-310p:
  vllm:
    arm64: quay.io/ascend/vllm-ascend:main-310p
    amd64: NONE
  mindie:
    arm64: harbor.tsingmao.com/xuanwu/mindie:2.3.0-300I-Duo-py311-openeuler24.03-lts
    amd64: NONE
  mlguider:
    arm64: harbor.tsingmao.com/mlguider/release:0123-xw-arm64
    amd64: NONE

