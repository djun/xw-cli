# XW Model Configuration
# This file defines AI models that can be deployed and served by xw.
#
# Configuration File Locations (in priority order):
#   1. Path specified in LoadModelsConfig(path)
#   2. XW_MODEL_CONFIG environment variable
#   3. /etc/xw/models.yaml (default)

version: "1.0"

models:
  # Qwen2 0.5B
  - model_id: qwen2-0.5b
    model_name: Qwen2 0.5B
    family: qwen
    version: "2.0"
    
    source:
      source_type: modelscope
      source_id: qwen/Qwen2-0.5B
      tag: main
    
    parameters: 0.5
    context_length: 32768
    required_vram_gb: 2
    
    supported_devices:
      - ascend-910b
      - ascend-310p
    
    backends:
      - type: vllm
        mode: docker
      - type: mindie
        mode: docker

  # Qwen2 7B
  - model_id: qwen2-7b
    model_name: Qwen2 7B
    family: qwen
    version: "2.0"
    
    source:
      source_type: modelscope
      source_id: qwen/Qwen2-7B
      tag: main
    
    parameters: 7.0
    context_length: 131072
    required_vram_gb: 16
    
    supported_devices:
      - ascend-910b
      - ascend-310p
    
    backends:
      - type: vllm
        mode: docker
      - type: mindie
        mode: docker
      - type: mlguider
        mode: docker

  # Qwen2 72B
  - model_id: qwen2-72b
    model_name: Qwen2 72B
    family: qwen
    version: "2.0"
    
    source:
      source_type: modelscope
      source_id: qwen/Qwen2-72B
      tag: main
    
    parameters: 72.0
    context_length: 131072
    required_vram_gb: 48
    
    supported_devices:
      - ascend-910b
    
    backends:
      - type: vllm
        mode: docker
      - type: mindie
        mode: docker

  # Qwen2.5 7B Instruct
  - model_id: qwen2.5-7b-instruct
    model_name: Qwen2.5 7B Instruct
    family: qwen
    version: "2.5"
    
    source:
      source_type: modelscope
      source_id: qwen/Qwen2.5-7B-Instruct
      tag: main
    
    parameters: 7.0
    context_length: 131072
    required_vram_gb: 16
    
    supported_devices:
      - ascend-910b
      - ascend-310p
    
    backends:
      - type: vllm
        mode: docker
      - type: mindie
        mode: docker
      - type: mlguider
        mode: docker

# Notes:
# - model_id: Unique identifier used throughout xw (e.g., "qwen2-7b")
# - source_type: modelscope, huggingface, local, git, http
# - supported_devices: Must match config_key from devices.yaml
# - backends: Listed in priority order, first available will be used
#   - type: vllm, mindie, mlguider
#   - mode: docker, native
